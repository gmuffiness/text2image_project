{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"이재철 stage 2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RVu-toYD_6aY","colab_type":"text"},"source":["Stage 2"]},{"cell_type":"markdown","metadata":{"id":"C86KsWc7_04L","colab_type":"text"},"source":["Residual block"]},{"cell_type":"markdown","metadata":{"id":"7Lhw0ESW_mAM","colab_type":"text"},"source":["  * The residual network having residual connections\n","  \n","    <img src=\"https://drive.google.com/uc?id=1ZqD1rYEg3wd6XA8LjRZo-JYsbIgQ1ro9\" width=\"500\">\n","\n"]},{"cell_type":"code","metadata":{"id":"0RZBDC5P_iTS","colab_type":"code","colab":{}},"source":["def residual_block(input):\n","    \"\"\"\n","    그래디언트가 잘 흐를 수 있도록 일종의 지름길(shortcut, skip connection)을 만들어 주자는 생각\n","    \"\"\"\n","    x = Conv2D(128 * 4, kernel_size=(3, 3), padding='same', strides=1)(input)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    x = Conv2D(128 * 4, kernel_size=(3, 3), strides=1, padding='same')(x)\n","    x = BatchNormalization()(x)\n","\n","    x = add([x, input])\n","    x = ReLU()(x)\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZXH-VLXwAhD8","colab_type":"text"},"source":["Stage 2 Generator"]},{"cell_type":"code","metadata":{"id":"O-0gLkV8AAZi","colab_type":"code","colab":{}},"source":["def joint_block(inputs): # 임베딩한 결과와 CA를 합침\n","    c = inputs[0]\n","    x = inputs[1]\n","\n","    c = K.expand_dims(c, axis=1)\n","    c = K.expand_dims(c, axis=1)\n","    c = K.tile(c, [1, 16, 16, 1])\n","    return K.concatenate([c, x], axis=3)\n","  \n","def build_stage2_generator():\n","    \"\"\"\n","    CA 네트워크를 포함한 stage 2 generator 생성\n","    \"\"\"\n","\n","    # 1. CA Augmentation Network\n","    input_layer = Input(shape=(1024,))\n","    input_lr_images = Input(shape=(64, 64, 3))\n","\n","    ca = Dense(256)(input_layer)\n","    mean_logsigma = LeakyReLU(alpha=0.2)(ca)\n","    c = Lambda(generate_c)(mean_logsigma)\n","\n","    # 2. Image Encoder\n","    x = ZeroPadding2D(padding=(1, 1))(input_lr_images)\n","    x = Conv2D(128, kernel_size=(3, 3), strides=1, use_bias=False)(x)\n","    x = ReLU()(x)\n","\n","    x = ZeroPadding2D(padding=(1, 1))(x)\n","    x = Conv2D(256, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    x = ZeroPadding2D(padding=(1, 1))(x)\n","    x = Conv2D(512, kernel_size=(4, 4), strides=2, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    # 3. Joint\n","    c_code = Lambda(joint_block)([c, x])\n","\n","    x = ZeroPadding2D(padding=(1, 1))(c_code)\n","    x = Conv2D(512, kernel_size=(3, 3), strides=1, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    # 4. Residual blocks\n","    x = residual_block(x)\n","    x = residual_block(x)\n","    x = residual_block(x)\n","    x = residual_block(x)\n","\n","    # 5. Upsampling blocks\n","    x = UpSampling2D(size=(2, 2))(x)\n","    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    x = UpSampling2D(size=(2, 2))(x)\n","    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    x = UpSampling2D(size=(2, 2))(x)\n","    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    x = UpSampling2D(size=(2, 2))(x)\n","    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n","    x = Activation('tanh')(x)\n","\n","    model = Model(inputs=[input_layer, input_lr_images], outputs=[x, mean_logsigma])\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"599DS3BUAeM-","colab_type":"text"},"source":["Stage 2 discriminator"]},{"cell_type":"code","metadata":{"id":"lPqOICAPAGY_","colab_type":"code","colab":{}},"source":["def build_stage2_discriminator():\n","    \"\"\"\n","    stage 2 discriminator 모델 만들기\n","    \"\"\"\n","    input_layer = Input(shape=(256, 256, 3))\n","\n","    x = Conv2D(64, (4, 4), padding='same', strides=2, input_shape=(256, 256, 3), use_bias=False)(input_layer)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = Dropout(0.3)(x)    \n","\n","\n","    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = Dropout(0.3)(x)    \n","\n","    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = Dropout(0.3)(x)    \n","\n","    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = Dropout(0.3)(x)    \n","\n","    x = Conv2D(1024, (4, 4), padding='same', strides=2, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x) \n","    x = Dropout(0.3)(x)    \n","\n","\n","    x = Conv2D(2048, (4, 4), padding='same', strides=2, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = Dropout(0.3)(x)    \n","\n","    x = Conv2D(1024, (1, 1), padding='same', strides=1, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = Dropout(0.3)(x)    \n","\n","    x = Conv2D(512, (1, 1), padding='same', strides=1, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.3)(x)    \n","\n","    x2 = Conv2D(128, (1, 1), padding='same', strides=1, use_bias=False)(x)\n","    x2 = BatchNormalization()(x2)\n","    x2 = LeakyReLU(alpha=0.2)(x2)\n","    x2 = Dropout(0.3)(x)    \n","\n","    x2 = Conv2D(128, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n","    x2 = BatchNormalization()(x2)\n","    x2 = LeakyReLU(alpha=0.2)(x2)\n","    x2 = Dropout(0.3)(x)    \n","\n","    x2 = Conv2D(512, (3, 3), padding='same', strides=1, use_bias=False)(x2)\n","    x2 = BatchNormalization()(x2)\n","    x2 = Dropout(0.3)(x)    \n","\n","    added_x = add([x, x2])\n","    added_x = LeakyReLU(alpha=0.2)(added_x)\n","\n","    input_layer2 = Input(shape=(4, 4, 128))\n","\n","    merged_input = concatenate([added_x, input_layer2])\n","\n","    x3 = Conv2D(64 * 8, kernel_size=1, padding=\"same\", strides=1)(merged_input)\n","    x3 = BatchNormalization()(x3)\n","    x3 = LeakyReLU(alpha=0.2)(x3)\n","    x3 = Flatten()(x3)\n","    x3 = Dense(1)(x3)\n","    x3 = Activation('sigmoid')(x3)\n","\n","    stage2_dis = Model(inputs=[input_layer, input_layer2], outputs=[x3])\n","    return stage2_dis"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D9XPqWWpAZdm","colab_type":"text"},"source":["Adversarial model"]},{"cell_type":"code","metadata":{"id":"8mciTvJgAKgw","colab_type":"code","colab":{}},"source":["def build_adversarial_model(gen_model2, dis_model, gen_model1):\n","    \"\"\"\n","    adversarial 모델 만들기\n","    \"\"\"\n","    embeddings_input_layer = Input(shape=(1024, ))\n","    noise_input_layer = Input(shape=(100, ))\n","    compressed_embedding_input_layer = Input(shape=(4, 4, 128))\n","\n","    gen_model1.trainable = False\n","    dis_model.trainable = False\n","\n","    lr_images, mean_logsigma1 = gen_model1([embeddings_input_layer, noise_input_layer])\n","    hr_images, mean_logsigma2 = gen_model2([embeddings_input_layer, lr_images])\n","    valid = dis_model([hr_images, compressed_embedding_input_layer])\n","\n","    model = Model(inputs=[embeddings_input_layer, noise_input_layer, compressed_embedding_input_layer], outputs=[valid, mean_logsigma2])\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YGeZ01YnAXTC","colab_type":"text"},"source":["Main "]},{"cell_type":"code","metadata":{"id":"FTu_XRyEAVrw","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","    # 경로 설정\n","    data_dir =\"/content/birds/birds\"\n","    train_dir = data_dir + \"/train\"\n","    test_dir = data_dir + \"/test\"\n","\n","    # 하이퍼파라미터 설정\n","    hr_image_size = (256, 256)\n","    lr_image_size = (64, 64)\n","    batch_size = 32\n","    z_dim = 100\n","    stage1_generator_lr = 0.0002\n","    stage1_discriminator_lr = 0.0002\n","    stage1_lr_decay_step = 600\n","    epochs = 600\n","    condition_dim = 128\n","\n","    # 경로 설정\n","    embeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n","    embeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n","\n","    filenames_file_path_train = train_dir + \"/filenames.pickle\"\n","    filenames_file_path_test = test_dir + \"/filenames.pickle\"\n","\n","    class_info_file_path_train = train_dir + \"/class_info.pickle\"\n","    class_info_file_path_test = test_dir + \"/class_info.pickle\"\n","\n","    cub_dataset_dir = \"/content/CUB_200_2011/CUB_200_2011\"\n","\n","    # 옵티마이저 설정\n","    dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n","    gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n","\n","    \"\"\"\n","   데이터 불러오기\n","    \"\"\"\n","    X_hr_train, y_hr_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\n","                                                            class_info_file_path=class_info_file_path_train,\n","                                                            cub_dataset_dir=cub_dataset_dir,\n","                                                            embeddings_file_path=embeddings_file_path_train,\n","                                                            image_size=(256, 256))\n","\n","    X_hr_test, y_hr_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\n","                                                         class_info_file_path=class_info_file_path_test,\n","                                                         cub_dataset_dir=cub_dataset_dir,\n","                                                         embeddings_file_path=embeddings_file_path_test,\n","                                                         image_size=(256, 256))\n","\n","    X_lr_train, y_lr_train, _ = load_dataset(filenames_file_path=filenames_file_path_train,\n","                                             class_info_file_path=class_info_file_path_train,\n","                                             cub_dataset_dir=cub_dataset_dir,\n","                                             embeddings_file_path=embeddings_file_path_train,\n","                                             image_size=(64, 64))\n","\n","    X_lr_test, y_lr_test, _ = load_dataset(filenames_file_path=filenames_file_path_test,\n","                                           class_info_file_path=class_info_file_path_test,\n","                                           cub_dataset_dir=cub_dataset_dir,\n","                                           embeddings_file_path=embeddings_file_path_test,\n","                                           image_size=(64, 64))\n","\n","    \"\"\"\n","    모델을 만들고 컴파일\n","    \"\"\"\n","    stage2_dis = build_stage2_discriminator()\n","    stage2_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n","\n","    stage1_gen = build_stage1_generator()\n","    stage1_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n","\n","    stage1_gen.load_weights(\"/content/gdrive/My Drive/딥러닝/results2/stage1_gen2.h5\")\n","\n","    stage2_gen = build_stage2_generator()\n","    stage2_gen.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n","\n","    embedding_compressor_model = build_embedding_compressor_model()\n","    embedding_compressor_model.compile(loss='binary_crossentropy', optimizer='adam')\n","\n","    adversarial_model = build_adversarial_model(stage2_gen, stage2_dis, stage1_gen)\n","    adversarial_model.compile(loss=['binary_crossentropy',wasserstein_loss], loss_weights=[1.0, 2.0],\n","                              optimizer=gen_optimizer, metrics=None)\n","\n","    tensorboard = TensorBoard(log_dir=\"/content/gdrive/My Drive/딥러닝/logs/\".format(time.time()))\n","    tensorboard.set_model(stage2_gen)\n","    tensorboard.set_model(stage2_dis)\n","\n","    # 진짜와 가짜 값들이 담긴 배열 생성\n","    # label smoothing 적용 (discriminator가 부드러운 형태로 확률을 예측하도록 하기 위해 실제 데이터에 대한 target 값을 1보다 약간 작은 값, 이를테면 0.9로 해준다는 것)\n","    # 정확한 건 (https://kangbk0120.github.io/articles/2017-08/tips-from-goodfellow)\n","    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n","    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n","\n","    for epoch in range(epochs):\n","        print(\"========================================\")\n","        print(\"Epoch is:\", epoch)\n","\n","        gen_losses = []\n","        dis_losses = []\n","\n","        # 데이터 불러오고 학습\n","        number_of_batches = int(X_hr_train.shape[0] / batch_size)\n","        print(\"Number of batches:{}\".format(number_of_batches))\n","        for index in range(number_of_batches):\n","            print(\"Batch:{}\".format(index+1))\n","\n","            # Create a noise vector\n","            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n","            X_hr_train_batch = X_hr_train[index * batch_size:(index + 1) * batch_size]\n","            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\n","            X_hr_train_batch = (X_hr_train_batch - 127.5) / 127.5\n","\n","            # 가짜 이미지 생성\n","            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\n","            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\n","\n","            \"\"\"\n","            4. Generate compressed embeddings\n","            \"\"\"\n","            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\n","            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\n","            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n","\n","            \"\"\"\n","            5. Train the discriminator model\n","            \"\"\"\n","            dis_loss_real = stage2_dis.train_on_batch([X_hr_train_batch, compressed_embedding],\n","                                                      np.reshape(real_labels, (batch_size, 1)))\n","            dis_loss_fake = stage2_dis.train_on_batch([hr_fake_images, compressed_embedding],\n","                                                      np.reshape(fake_labels, (batch_size, 1)))\n","            dis_loss_wrong = stage2_dis.train_on_batch([X_hr_train_batch[:(batch_size - 1)], compressed_embedding[1:]],\n","                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\n","            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong,  dis_loss_fake))\n","            print(\"d_loss:{}\".format(d_loss))\n","\n","            \"\"\"\n","            Train the adversarial model\n","            \"\"\"\n","            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],\n","                                                                [K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n","\n","            print(\"g_loss:{}\".format(g_loss))\n","\n","            dis_losses.append(d_loss)\n","            gen_losses.append(g_loss)\n","            adversarial_model.save('/content/gdrive/My Drive/딥러닝/results2/my_stackganmodel2.h5')    \n","            stage2_gen.save('/content/gdrive/My Drive/딥러닝/results2/my_genmodel2.h5')    \n","            stage2_dis.save('/content/gdrive/My Drive/딥러닝/results2/my_dismodel2.h5')    \n","            \"\"\"\n","            각 에폭 끝나고 tensorboard에 loss값들 저장하는 부분\n","            \"\"\"\n","            write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n","            write_log(tensorboard, 'generator_loss', np.mean(gen_losses[0]), epoch)\n","\n","\n","        # 2 에폭마다 이미지 생성\n","        if epoch % 2 == 0:\n","            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n","            embedding_batch = embeddings_test[0:batch_size]\n","\n","            lr_fake_images, _ = stage1_gen.predict([embedding_batch, z_noise2], verbose=3)\n","            hr_fake_images, _ = stage2_gen.predict([embedding_batch, lr_fake_images], verbose=3)\n","            stage2_gen.save_weights(\"/content/gdrive/My Drive/딥러닝/results2/stage2_gen.h5\")\n","            stage2_dis.save_weights(\"/content/gdrive/My Drive/딥러닝/results2/stage2_dis.h5\")\n","            # Save images\n","            for i, img in enumerate(lr_fake_images[:10]):\n","                save_rgb_img(img, \"/content/gdrive/My Drive/딥러닝/results2/gen_{}_{}.png\".format(epoch, i))\n","            for i, img in enumerate(hr_fake_images[:10]):\n","                save_rgb_img(img, \"/content/gdrive/My Drive/딥러닝/results2/gen_{}_{}.png\".format(epoch, i))\n","\n","    adversarial_model.save('/content/gdrive/My Drive/딥러닝/results2/my_stackganmodel.h5')    \n","    stage2_gen.save('/content/gdrive/My Drive/딥러닝/results2/my_genmodel.h5')    \n","    stage2_dis.save('/content/gdrive/My Drive/딥러닝/results2/my_dismodel.h5')  "],"execution_count":null,"outputs":[]}]}