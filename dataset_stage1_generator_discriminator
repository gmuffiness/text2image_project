{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataset/stage1_generator_discriminator","provenance":[{"file_id":"1vHEt8XUqfFFcJeMfiz8wURfhKBNr3d0y","timestamp":1592308430375}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0KV9OIEe9DXn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1592371131211,"user_tz":-540,"elapsed":15712,"user":{"displayName":"문대정","photoUrl":"","userId":"12686300660117063511"}},"outputId":"e198b42e-1984-4e2d-a0bb-322557312ffe"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zY6dWr4XdtAe","colab_type":"code","colab":{}},"source":["import os\n","import tarfile\n","\n","fname = '/content/gdrive/My Drive/dl_teamproject_folder/CUB_200_2011/CUB_200_2011.tgz'  # 압축 파일을 지정해주고   \n","ap = tarfile.open(fname)      # 열어줍니다. \n","\n","ap.extractall('/content/gdrive/My Drive/dl_teamproject_folder/CUB_200_2011/')         # 그리고는 압축을 풀어줍니다. \n","# () 안에는 풀고 싶은 경로를 넣어주면 되요. 비워둘 경우 현재 경로에 압축 풉니다. \n"," \n","ap.close()  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KIegGWV5aON0","colab_type":"text"},"source":["# Importing Libraries"]},{"cell_type":"code","metadata":{"id":"0TjLKTwFcHZ1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592371141367,"user_tz":-540,"elapsed":2465,"user":{"displayName":"문대정","photoUrl":"","userId":"12686300660117063511"}},"outputId":"01bde66c-a34e-4348-ffdc-7ec27cd9ea2a"},"source":["import os\n","import pickle\n","import random\n","import time\n","\n","import PIL\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from PIL import Image\n","from keras import Input, Model\n","from keras import backend as K\n","from keras.callbacks import TensorBoard\n","from keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, \\\n","    concatenate, Flatten, Lambda, Concatenate\n","from keras.optimizers import Adam\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"7pycIMXgaTtW","colab_type":"text"},"source":["# Loading of Dataset"]},{"cell_type":"code","metadata":{"id":"PHs4UNm2eTWA","colab_type":"code","colab":{}},"source":["#pickle(텍스트가 아닌 객체 자체인 파일 ex.list) 불러오기 위한 함수 (labels저장된 파일)\n","def load_class_ids(class_info_file_path):\n","    with open(class_info_file_path, 'rb') as f:\n","        class_ids = pickle.load(f, encoding='latin1')\n","        return class_ids\n","       \n","#임베딩     \n","def load_embeddings(embeddings_file_path):\n","    with open(embeddings_file_path, 'rb') as f:\n","        embeddings = pickle.load(f, encoding='latin1')\n","        embeddings = np.array(embeddings)\n","        print('embeddings: ', embeddings.shape)\n","    return embeddings\n","\n","#pickle 파일이름 불러오기\n","def load_filenames(filenames_file_path):\n","    with open(filenames_file_path, 'rb') as f:\n","        filenames = pickle.load(f, encoding='latin1')\n","    return filenames\n","\n","#image detection위한 bounding box(바운딩 박스와 일치하는 파일의 dictionary 불러오기) \n","def load_bounding_boxes(dataset_dir):\n","    # Paths\n","    bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')\n","    file_paths_path = os.path.join(dataset_dir, 'images.txt')\n","\n","    # Read bounding_boxes.txt and images.txt file\n","    df_bounding_boxes = pd.read_csv(bounding_boxes_path,\n","                                    delim_whitespace=True, header=None).astype(int) #delim_whitespace : 공백으로 구분된 값 파일 읽기\n","    df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)\n","\n","    # Create a list of file names\n","    file_names = df_file_names[1].tolist()\n","\n","    # Create a dictionary of file_names and bounding boxes\n","    filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}\n","\n","    # Assign a bounding box to the corresponding image\n","    for i in range(0, len(file_names)):\n","        # Get the bounding box\n","        bounding_box = df_bounding_boxes.iloc[i][1:].tolist()\n","        key = file_names[i][:-4]\n","        filename_boundingbox_dict[key] = bounding_box\n","\n","    return filename_boundingbox_dict\n","\n","#image 바운딩 박스로 자르고, 주어진 사이즈로 이미지 resize\n","def get_img(img_path, bbox, image_size):\n","    img = Image.open(img_path).convert('RGB')\n","    width, height = img.size\n","    if bbox is not None:\n","        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n","        center_x = int((2 * bbox[0] + bbox[2]) / 2)\n","        center_y = int((2 * bbox[1] + bbox[3]) / 2)\n","        y1 = np.maximum(0, center_y - R)\n","        y2 = np.minimum(height, center_y + R)\n","        x1 = np.maximum(0, center_x - R)\n","        x2 = np.minimum(width, center_x + R)\n","        img = img.crop([x1, y1, x2, y2])\n","    img = img.resize(image_size, PIL.Image.BILINEAR)\n","    return img\n"," \n"," #트레이닝하기 위한 데이터셋 로드 : image, labels, 일치하는 embedding return\n","def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):\n","    filenames = load_filenames(filenames_file_path)\n","    class_ids = load_class_ids(class_info_file_path)\n","    bounding_boxes = load_bounding_boxes(cub_dataset_dir)\n","    all_embeddings = load_embeddings(embeddings_file_path)\n","\n","    X, y, embeddings = [], [], []\n","    print(\"Embeddings shape:\", all_embeddings.shape)\n","\n","    for index, filename in enumerate(filenames):\n","        bounding_box = bounding_boxes[filename]\n","        try:\n","            img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)\n","            img = get_img(img_name, bounding_box, image_size)\n","\n","            all_embeddings1 = all_embeddings[index, :, :]\n","\n","            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)#0과 임베딩크기 사이 정수 랜덤반환\n","            embedding = all_embeddings1[embedding_ix, :]\n","\n","            X.append(np.array(img))\n","            y.append(class_ids[index])\n","            embeddings.append(embedding)\n","        except Exception as e:\n","            print(e)\n","\n","    X = np.array(X)\n","    y = np.array(y)\n","    embeddings = np.array(embeddings)\n","    return X, y, embeddings"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SHG799svaZA9","colab_type":"text"},"source":["#  Model Creation"]},{"cell_type":"code","metadata":{"id":"Fnamu5fjeXv8","colab_type":"code","colab":{}},"source":["def generate_c(x):\n","    mean = x[:, :128] #(batch,128)dims의 tensor생성\n","    log_sigma = x[:, 128:]\n","    stddev = K.exp(log_sigma) #from keras import backend as K | exp = exponential\n","    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))  # random normal vector with mean=0 and std=1.0\n","    c = stddev * epsilon + mean #text conditioning variable 계산 | 모델 아키텍쳐 그림 중에서 c0 햇 부분\n","    return c\n","\n","#conditioning augmentation: text embedding vector를 conditioning latent variables로 변환  \n","def build_ca_model():\n","    input_layer = Input(shape=(1024,))\n","    x = Dense(256)(input_layer)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    model = Model(inputs=[input_layer], outputs=[x])\n","    return model  # Takes an embedding of shape (1024,) and returns a tensor of shape (256,)\n","  \n","def build_embedding_compressor_model():\n","    input_layer = Input(shape=(1024,))\n","    x = Dense(128)(input_layer)\n","    x = ReLU()(x)\n","    model = Model(inputs=[input_layer], outputs=[x])\n","    return model\n","\n","\n","def build_stage1_generator():\n","    input_layer = Input(shape=(1024,)) #noise variable\n","    x = Dense(256)(input_layer)\n","    mean_logsigma = LeakyReLU(alpha=0.2)(x)\n","\n","    c = Lambda(generate_c)(mean_logsigma)\n","\n","    input_layer2 = Input(shape=(100,))\n","\n","    gen_input = Concatenate(axis=1)([c, input_layer2]) #text-conditioning variable/noise variable\n","\n","    x = Dense(128 * 8 * 4 * 4, use_bias=False)(gen_input)\n","    x = ReLU()(x)\n","\n","    x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x) #2d tensor->4d tensor로 변환\n","\n","    x = UpSampling2D(size=(2, 2))(x)\n","    x = Conv2D(512, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n","    x = BatchNormalization()(x) #bn 사용 - > bias=False\n","    x = ReLU()(x)\n","\n","    x = UpSampling2D(size=(2, 2))(x)\n","    x = Conv2D(256, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    x = UpSampling2D(size=(2, 2))(x)\n","    x = Conv2D(128, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    x = UpSampling2D(size=(2, 2))(x)\n","    x = Conv2D(64, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    x = Conv2D(3, kernel_size=3, padding=\"same\", strides=1, use_bias=False)(x)\n","    x = Activation(activation='tanh')(x) #저해상도 이미지 생성할 generator\n","\n","    stage1_gen = Model(inputs=[input_layer, input_layer2], outputs=[x, mean_logsigma])\n","    stage1_gen.summary()\n","\n","    return stage1_gen"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHvK2VzuebDk","colab_type":"code","colab":{}},"source":["# 이미지 저장\n","def save_rgb_img(img, path):\n","    fig = plt.figure()\n","    ax = fig.add_subplot(1, 1, 1)\n","    ax.imshow(img)\n","    ax.axis(\"off\")\n","    ax.set_title(\"Image\")\n","\n","    plt.savefig(path)\n","    plt.close()\n","\n","#텐서보드에 summary기록   \n","def write_log(callback, name, loss, batch_no):\n","    summary = tf.Summary()\n","    summary_value = summary.value.add()\n","    summary_value.simple_value = loss\n","    summary_value.tag = name\n","    callback.writer.add_summary(summary, batch_no)\n","    callback.writer.flush()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32ZNlyE4_CPg","colab_type":"text"},"source":["===="]},{"cell_type":"code","metadata":{"id":"X6wFBKBgefMD","colab_type":"code","colab":{}},"source":["def build_stage1_discriminator():\n","    \"\"\"\n","    discriminator는 모델 아키텍쳐 그림에서처럼 2개의 input을 받는다 \n","    1) generator거쳐서 upsampling된 네트워크를 다시 downsampling해서 만든 3차원의 4x4x512의 네트워크\n","    2) 3번에서 concatenate하기 위해 embedding layer를 같은 shape으로 만들어준다. 4x4x128 \n","    3. Concatenate 시키고, 마지막 로짓값(0~1)을 얻기 위해 마지막 모듈(merged_input ~ x2)로 넣어준다.\n","    \"\"\"\n","    input_layer = Input(shape=(64, 64, 3))\n","\n","    x = Conv2D(64, (4, 4),\n","               padding='same', strides=2,\n","               input_shape=(64, 64, 3), use_bias=False)(input_layer)\n","    x = LeakyReLU(alpha=0.2)(x)\n","\n","    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","\n","    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","\n","    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","\n","    input_layer2 = Input(shape=(4, 4, 128))\n","\n","    merged_input = concatenate([x, input_layer2])\n","\n","    x2 = Conv2D(64 * 8, kernel_size=1,\n","                padding=\"same\", strides=1)(merged_input)\n","    x2 = BatchNormalization()(x2)\n","    x2 = LeakyReLU(alpha=0.2)(x2)\n","    x2 = Flatten()(x2)\n","    x2 = Dense(1)(x2)\n","    x2 = Activation('sigmoid')(x2)\n","\n","    stage1_dis = Model(inputs=[input_layer, input_layer2], outputs=[x2])\n","    return stage1_dis"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"awq_9gAP_EGV","colab_type":"code","colab":{}},"source":["def build_adversarial_model(gen_model, dis_model):\n","    input_layer = Input(shape=(1024,)) # 1024 = stage1_generator에 들어갈 input size\n","    input_layer2 = Input(shape=(100,)) # 100 = noise 변수의 input size\n","    input_layer3 = Input(shape=(4, 4, 128)) \n","\n","    x, mean_logsigma = gen_model([input_layer, input_layer2]) # stage1_gen 처럼 나온 output\n","\n","    dis_model.trainable = False\n","    valid = dis_model([x, input_layer3]) # stage1_gen 처럼 나온 output과 임베딩 logit값?\n","\n","    model = Model(inputs=[input_layer, input_layer2, input_layer3], outputs=[valid, mean_logsigma])\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T3BNs5n__P94","colab_type":"text"},"source":["# Defining Loss"]},{"cell_type":"code","metadata":{"id":"2c7a_PbH_Vwu","colab_type":"code","colab":{}},"source":["def KL_loss(y_true, y_pred):\n","    mean = y_pred[:, :128]\n","    logsigma = y_pred[:, :128]\n","    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\n","    loss = K.mean(loss)\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5LDXcjx4-19Z","colab_type":"text"},"source":["# Main File"]},{"cell_type":"code","metadata":{"id":"3JUeRDH4RXfN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"244bf8eb-cd90-4bed-c695-982ae539342b"},"source":["if __name__ == '__main__':\n","\n","    # 폴더 경로 설정\n","    data_dir = \"/content/gdrive/My Drive/dl_teamproject_folder/birds/\"\n","    train_dir = data_dir + \"/train\"\n","    test_dir = data_dir + \"/test\"\n","\n","    # 하이퍼 파라미터 설정\n","    image_size = 64\n","    batch_size = 1\n","    z_dim = 100\n","    stage1_generator_lr = 0.0002\n","    stage1_discriminator_lr = 0.0002\n","    stage1_lr_decay_step = 600\n","    epochs = 2\n","    condition_dim = 128\n","\n","    #폴더 경로 설정\n","    embeddings_file_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n","    embeddings_file_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n","\n","    filenames_file_path_train = train_dir + \"/filenames.pickle\"\n","    filenames_file_path_test = test_dir + \"/filenames.pickle\"\n","\n","    class_info_file_path_train = train_dir + \"/class_info.pickle\"\n","    class_info_file_path_test = test_dir + \"/class_info.pickle\"\n","\n","    cub_dataset_dir = \"/content/gdrive/My Drive/dl_teamproject_folder/CUB_200_2011/CUB_200_2011\"\n","    \n","    # optimizer 정의\n","    dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n","    gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n","\n","    \"\"\"\"\n","    데이터 불러오기\n","    \"\"\"\n","    X_train, y_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,\n","                                                      class_info_file_path=class_info_file_path_train,\n","                                                      cub_dataset_dir=cub_dataset_dir,\n","                                                      embeddings_file_path=embeddings_file_path_train,\n","                                                      image_size=(64, 64))\n","\n","    X_test, y_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,\n","                                                   class_info_file_path=class_info_file_path_test,\n","                                                   cub_dataset_dir=cub_dataset_dir,\n","                                                   embeddings_file_path=embeddings_file_path_test,\n","                                                   image_size=(64, 64))\n","\n","    \"\"\"\n","    네트워크 만들고 컴파일\n","    \"\"\"\n","    ca_model = build_ca_model()\n","    ca_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n","\n","    stage1_dis = build_stage1_discriminator()\n","    stage1_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n","\n","    stage1_gen = build_stage1_generator()\n","    stage1_gen.compile(loss=\"mse\", optimizer=gen_optimizer)\n","\n","    embedding_compressor_model = build_embedding_compressor_model()\n","    embedding_compressor_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n","\n","    adversarial_model = build_adversarial_model(gen_model=stage1_gen, dis_model=stage1_dis)\n","    adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1, 2.0],\n","                              optimizer=gen_optimizer, metrics=None)\n","\n","    tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n","    tensorboard.set_model(stage1_gen)\n","    tensorboard.set_model(stage1_dis)\n","    tensorboard.set_model(ca_model)\n","    tensorboard.set_model(embedding_compressor_model)\n","\n","    # 진짜와 가짜 값들이 담긴 배열 생성\n","    # label smoothing 적용 (discriminator가 부드러운 형태로 확률을 예측하도록 하기 위해 실제 데이터에 대한 target 값을 1보다 약간 작은 값, 이를테면 0.9로 해준다는 것)\n","    # 정확한 건 (https://kangbk0120.github.io/articles/2017-08/tips-from-goodfellow)\n","    real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n","    fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n","\n","    for epoch in range(epochs):\n","        print(\"========================================\")\n","        print(\"Epoch is:\", epoch)\n","        print(\"Number of batches\", int(X_train.shape[0] / batch_size))\n","\n","        gen_losses = []\n","        dis_losses = []\n","\n","        # 데이터와 train 모델 불러오기\n","        number_of_batches = int(X_train.shape[0] / batch_size)\n","        for index in range(number_of_batches):\n","            print(\"Batch:{}\".format(index+1))\n","            \n","            \"\"\"\n","            Discriminator network 학습\n","            \"\"\"\n","            # 배치 사이즈 만큼의 데이터를 샘플링한다 Sample a batch of data\n","            z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n","            image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n","            embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]\n","            image_batch = (image_batch - 127.5) / 127.5\n","\n","            # 가짜 이미지 생성\n","            fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\n","\n","            # compressed된 embedding 생성\n","            compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)\n","            compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))\n","            # 배열을 반복하면서 새로운 축(axis)을 추가하는 np.tile\n","            compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n","\n","            # 진짜 이미지에 진짜라는 라벨(1)을 주고 discriminator 학습시킨 loss \n","            dis_loss_real = stage1_dis.train_on_batch([image_batch, compressed_embedding],\n","                                                      np.reshape(real_labels, (batch_size, 1)))\n","            # generator가 생성한 가짜 이미지에 가짜라는 라벨(0)을 주고 discriminator 학습시킨 loss \n","            dis_loss_fake = stage1_dis.train_on_batch([fake_images, compressed_embedding],\n","                                                      np.reshape(fake_labels, (batch_size, 1)))\n","            # 진짜 이미지에 가짜라는 라벨(0)주고 discriminator 학습시킨 loss \n","            dis_loss_wrong = stage1_dis.train_on_batch([image_batch[:(batch_size - 1)], compressed_embedding[1:]],\n","                                                       np.reshape(fake_labels[1:], (batch_size-1, 1)))\n","            # 총 discriminator의 loss = 0.5 * (loss_real + 0.5 * (loss_wrong + loss_fake)) \n","            d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake))\n","\n","            print(\"d_loss_real:{}\".format(dis_loss_real))\n","            print(\"d_loss_fake:{}\".format(dis_loss_fake))\n","            print(\"d_loss_wrong:{}\".format(dis_loss_wrong))\n","            print(\"d_loss:{}\".format(d_loss))\n","\n","            \"\"\"\n","            Generator network 학습\n","            \"\"\"\n","            g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],[K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n","            print(\"g_loss:{}\".format(g_loss))\n","\n","            dis_losses.append(d_loss)\n","            gen_losses.append(g_loss)\n","\n","        \"\"\"\n","        각 에폭 끝나고 tensorboard에 loss값들 저장하는 부분\n","        \"\"\"\n","        write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n","        write_log(tensorboard, 'generator_loss', np.mean(gen_losses[0]), epoch)\n","        \n","        # 짝수번째 에폭 학습 끝날때마다 이미지 생성하고 저장하는 부분\n","        if epoch % 2 == 0:\n","            # z_noise2 = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n","            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n","            embedding_batch = embeddings_test[0:batch_size]\n","            fake_images, _ = stage1_gen.predict_on_batch([embedding_batch, z_noise2])\n","\n","            # Save images\n","            for i, img in enumerate(fake_images[:10]):\n","                save_rgb_img(img, \"results/gen_{}_{}.png\".format(epoch, i))\n","\n","    # Save models\n","    stage1_gen.save_weights(\"stage1_gen.h5\")\n","    stage1_dis.save_weights(\"stage1_dis.h5\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["embeddings:  (8855, 10, 1024)\n","Embeddings shape: (8855, 10, 1024)\n"],"name":"stdout"}]}]}